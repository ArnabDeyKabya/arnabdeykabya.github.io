export const research = {
  thesis: {
    title: "Adversarial Machine Learning for Cyber Security: Defense and Detection Mechanisms",
    description:
      "Exploring defense mechanisms against adversarial attacks in machine learning systems, with focus on intrusion detection and secure AI deployment.",
    status: "In Progress",
    year: "2024-2025",
  },
  interests: [
    {
      area: "Cyber Security",
      description:
        "Focus on adversarial machine learning, intrusion detection, and defense mechanisms against backdoor and side-channel attacks.",
    },
    {
      area: "Machine Learning",
      description:
        "Deep learning, interpretability (XAI with SHAP/LIME), and applications in healthcare, biometric authentication, and intelligent systems.",
    },
    {
      area: "Generative AI",
      description:
        "Large Language Models, prompt engineering, and secure deployment of generative models for real-world tasks.",
    },
    {
      area: "5G and Next-Generation Networks",
      description:
        "Security, low-latency communication, and intelligent applications leveraging edge computing and IoT integration.",
    },
  ],
  publications: [
    {
      title: "Seg2Reg-Net: An Explainable AI Analysis of Predictive Limitations in Cattle Weight Estimation",
      authors: "Arnab Dey, et al.",
      venue: "NSysS 2025",
      status: "Published",
      year: "2025",
      description:
        "Proposed Seg2Reg-Net, an end-to-end Attention U-Net + regression framework for cattle weight estimation. Incorporated explainable AI (LIME, SHAP) to expose predictive limitations and spurious correlations.",
      link: "https://dl.acm.org/doi/10.1145/3777555.3777559",
    },
  ],
}

export const researchInterests = [
  {
    area: "Cyber Security",
    description:
      "Focus on adversarial machine learning, intrusion detection, and defense mechanisms against backdoor and side-channel attacks.",
    topics: ["Adversarial ML", "Intrusion Detection", "Backdoor Attacks", "Side-Channel Attacks"],
  },
  {
    area: "Machine Learning",
    description:
      "Deep learning, interpretability (XAI with SHAP/LIME), and applications in healthcare, biometric authentication, and intelligent systems.",
    topics: ["Deep Learning", "Explainable AI", "Healthcare AI", "Biometric Authentication"],
  },
  {
    area: "Natural Language Processing",
    description:
      "Efficient and verifiable machine unlearning techniques, privacy-preserving model updates, and mitigation of sensitive or harmful information in trained models.",
    topics: [
      "Machine Unlearning",
      "Data Privacy",
      "Model Sanitization",
      "Verifiable Unlearning",
      "Trustworthy AI",
    ],
  },
]

export const publications = [
  {
    title: "Seg2Reg-Net: An Explainable AI Analysis of Predictive Limitations in Cattle Weight Estimation",
    authors: "Arnab Dey, et al.",
    venue: "NSysS 2025",
    status: "Published",
    year: "2025",
    highlights: [
      "Proposed Seg2Reg-Net, an end-to-end Attention U-Net + regression framework for cattle weight estimation",
      "Incorporated explainable AI (LIME, SHAP) to expose predictive limitations and spurious correlations",
    ],
    link: "https://dl.acm.org/doi/10.1145/3777555.3777559",
  },
  {
    title: "Seeing the Invisible: Grad-CAM-Driven Detection of Sparse and Imperceptible Backdoor Attacks",
    authors: "Arnab Dey, et al.",
    venue: "QPAIN 2026",
    status: "Under Review",
    year: "2025",
    highlights: [
      "Proposed a Grad-CAMâ€“based model comparison framework for detecting sparse and invisible backdoor attacks (SIBA)",
      "Extracted statistical, spatial, similarity, and gradient features from attention differences for supervised detection",
    ],
    link: "", // add IEEE Xplore / proceedings link if available
  },
];

